{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20d30e09-8c32-4776-9e33-a7255add9007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 119 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /home/sultan/miniconda3/lib/python3.9/site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: tqdm in /home/sultan/miniconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (4.61.2)\n",
      "Requirement already satisfied: click in /home/sultan/miniconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (8.0.3)\n",
      "Requirement already satisfied: joblib in /home/sultan/miniconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/sultan/miniconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (2022.1.18)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66b977b8-d798-4e19-beb1-7842668c445e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/sultan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/sultan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f313333f-67a9-468b-8e59-63dd86821bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizing Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53f7d915-2c59-423a-8422-043d62e3f930",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a583ba12-6a4b-4d73-9ffe-c159e593fa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatized'] = df[\"cleaned\"].apply(lambda x: \" \".join(Word(word).lemmatize() for word in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d188011-f98f-4b86-bab1-f371a9bd1588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stop_words</th>\n",
       "      <th>reviews_lower</th>\n",
       "      <th>rmv_punc</th>\n",
       "      <th>rmv_punc_stp</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Consider the Tesla Model 3. Mine is fun, which...</td>\n",
       "      <td>41</td>\n",
       "      <td>230</td>\n",
       "      <td>4.609756</td>\n",
       "      <td>14</td>\n",
       "      <td>consider the tesla model 3. mine is fun, which...</td>\n",
       "      <td>consider the tesla model mine is fun which bri...</td>\n",
       "      <td>consider tesla model mine fun brings joy conte...</td>\n",
       "      <td>consider tesla model mine fun brings joy conte...</td>\n",
       "      <td>consider tesla model mine fun brings joy conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My experience with Tesla has been nothing shor...</td>\n",
       "      <td>397</td>\n",
       "      <td>2066</td>\n",
       "      <td>4.204030</td>\n",
       "      <td>155</td>\n",
       "      <td>my experience with tesla has been nothing shor...</td>\n",
       "      <td>my experience with tesla has been nothing shor...</td>\n",
       "      <td>experience tesla nothing short complete disast...</td>\n",
       "      <td>experience tesla nothing short complete disast...</td>\n",
       "      <td>experience tesla nothing short complete disast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is for our amazing experience with the se...</td>\n",
       "      <td>110</td>\n",
       "      <td>587</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>49</td>\n",
       "      <td>this is for our amazing experience with the se...</td>\n",
       "      <td>this is for our amazing experience with the se...</td>\n",
       "      <td>amazing experience service center went beyond ...</td>\n",
       "      <td>amazing experience service center went beyond ...</td>\n",
       "      <td>amazing experience service center went beyond ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kevin and Bridget were amazing. I purchased a ...</td>\n",
       "      <td>127</td>\n",
       "      <td>703</td>\n",
       "      <td>4.543307</td>\n",
       "      <td>57</td>\n",
       "      <td>kevin and bridget were amazing. i purchased a ...</td>\n",
       "      <td>kevin and bridget were amazing i purchased a u...</td>\n",
       "      <td>kevin bridget amazing purchased used tesla abs...</td>\n",
       "      <td>kevin bridget amazing purchased used tesla abs...</td>\n",
       "      <td>kevin bridget amazing purchased used tesla ab ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Do you love having your car held hostage for t...</td>\n",
       "      <td>59</td>\n",
       "      <td>309</td>\n",
       "      <td>4.254237</td>\n",
       "      <td>24</td>\n",
       "      <td>do you love having your car held hostage for t...</td>\n",
       "      <td>do you love having your car held hostage for t...</td>\n",
       "      <td>love car held hostage things arent fault locat...</td>\n",
       "      <td>love car held hostage things arent fault locat...</td>\n",
       "      <td>love car held hostage thing arent fault locati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  word_count  char_count  \\\n",
       "0  Consider the Tesla Model 3. Mine is fun, which...          41         230   \n",
       "1  My experience with Tesla has been nothing shor...         397        2066   \n",
       "2  This is for our amazing experience with the se...         110         587   \n",
       "3  Kevin and Bridget were amazing. I purchased a ...         127         703   \n",
       "4  Do you love having your car held hostage for t...          59         309   \n",
       "\n",
       "   avg_word  stop_words                                      reviews_lower  \\\n",
       "0  4.609756          14  consider the tesla model 3. mine is fun, which...   \n",
       "1  4.204030         155  my experience with tesla has been nothing shor...   \n",
       "2  4.300000          49  this is for our amazing experience with the se...   \n",
       "3  4.543307          57  kevin and bridget were amazing. i purchased a ...   \n",
       "4  4.254237          24  do you love having your car held hostage for t...   \n",
       "\n",
       "                                            rmv_punc  \\\n",
       "0  consider the tesla model mine is fun which bri...   \n",
       "1  my experience with tesla has been nothing shor...   \n",
       "2  this is for our amazing experience with the se...   \n",
       "3  kevin and bridget were amazing i purchased a u...   \n",
       "4  do you love having your car held hostage for t...   \n",
       "\n",
       "                                        rmv_punc_stp  \\\n",
       "0  consider tesla model mine fun brings joy conte...   \n",
       "1  experience tesla nothing short complete disast...   \n",
       "2  amazing experience service center went beyond ...   \n",
       "3  kevin bridget amazing purchased used tesla abs...   \n",
       "4  love car held hostage things arent fault locat...   \n",
       "\n",
       "                                             cleaned  \\\n",
       "0  consider tesla model mine fun brings joy conte...   \n",
       "1  experience tesla nothing short complete disast...   \n",
       "2  amazing experience service center went beyond ...   \n",
       "3  kevin bridget amazing purchased used tesla abs...   \n",
       "4  love car held hostage things arent fault locat...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  consider tesla model mine fun brings joy conte...  \n",
       "1  experience tesla nothing short complete disast...  \n",
       "2  amazing experience service center went beyond ...  \n",
       "3  kevin bridget amazing purchased used tesla ab ...  \n",
       "4  love car held hostage thing arent fault locati...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6da229b9-b8df-411d-9562-6078d42f747b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"lemmatized.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
